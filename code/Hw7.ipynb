{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.1 The dataset 'motor contains data based on a simulated motorcycle accident used to test helmets. The variables are the time after impact 'time' and head acceleration of a crash test dummy 'accel'**\n",
    "\n",
    "*(a) Find the local linear kernel regression estimator of E(accel|time) choosing the smoothing parameter h subjectively balancing the goal of having a smooth function with the need to have the function accurately represent the relationship between the variables. Plot the estimated regression function together with the data.*\n",
    "\n",
    "*(b) Repeat part (a) using cross validation to choose the smoothing parameter. Plot the estimated regression function together with the raw data; compare the estimate to the one found in part (a)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_loc<-'/Users/Alexis/Documents/Spring2020/nonparametrics/data/motor.csv'\n",
    "data_loc<-'/Users/aporter1350/Documents/Courses/Spring2020/nonparametrics/data/motor.csv'\n",
    "motor<-read.csv(data_loc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.2 Using the dataset 'geyser'. Estimate the regression function relating duration (response variable) to waiting (predictor). Use a local linear kernel estimator and use cross validation to choose the smoothing parameter. Plot the estimated regression function with the data and comment on how the duration of an eruption is related to the time since the last eruption.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_loc<-'/Users/Alexis/Documents/Spring2020/nonparametrics/data/geyser.csv'\n",
    "data_loc<-'/Users/aporter1350/Documents/Courses/Spring2020/nonparametrics/data/geyser.csv'\n",
    "geyser<-read.csv(data_loc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.3 The amount of scoring in baseball has changed over the years with changes in rules, athletic training, etc. Such changes complicate comparisons of players and teams from different eras; hence, it is often useful to standardize certain results using some measure of scoring in a given year. The dataset 'runs' contains the avg runs scored per team per game in each year from 1900-2016**\n",
    "\n",
    "*(a) Calculate the local linear kernel estimate of the regression function relating runs to year. Choose the value of the smoothing parameter using cross-validation. Give a plot of the estimate together with the data.*\n",
    "\n",
    "*(b) Give the value of the estimated regression function for the years 1920, 1940, 1960, 1980, 2000, 2016.*\n",
    "\n",
    "*(c) Repeat parts (a) and (b) taking the value of the smoothing parameter to be 1.5 times the cross-validation value (using hmult). How do the estimates found here for 1020, 1940, 1960, 1980, 2000, and 2016 compare to those found in part (b)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_loc<-'/Users/Alexis/Documents/Spring2020/nonparametrics/data/runs.csv'\n",
    "data_loc<-'/Users/aporter1350/Documents/Courses/Spring2020/nonparametrics/data/runs.csv'\n",
    "runs<-read.csv(data_loc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.4 In section 7.3 we saw that the value of h that minimizes the MSE is of order $O(\\frac{1}{n^{1/5}})$ as n approaches infinity. The purpose of this exercise is to investigate whether the cross-validation choice of h is of this order. One approach to this issue is to derive analytically the properties of hcv; however, such an analysis is quite complicated. Hence, here we consider a more empirical approach. This method is useful for investigating the order of a term, without doing a lot of theoretical calculations.**\n",
    "\n",
    "*(a) For n=100 use the function runif to draw n random variates from a uniform distribution on the interval (0,1) and assign the values to x*\n",
    "\n",
    "*(b) Construct a vector y using *\n",
    "\n",
    "> y <- x^2 + rnorm(n, sd=1/2)\n",
    "\n",
    "*That is, the true regression function here is $m(x)=x^2$. Other functions could be used here, with similar results.*\n",
    "\n",
    "*(c) Use the function sm.regression to obtain the cross-validation value of the smoothing parameter h corresponding to the values of x and y, using a local constant estimator. Thus the value of h is given by*\n",
    "\n",
    "> sm.regression(x, y, method=\"cv\", poly.index=0)$h\n",
    "\n",
    "*(d) Repeat parts (b) and (c) four times (so you have five values) and average the results. This give an estimate of $h_{cv}$* for n=100 call this estimate $\\hat{h}_{100}$\n",
    "\n",
    "*(e) Repeat parts (a)-(d) for n=500, 1000,5000, 10,000 to obtain $\\hat{h}_{500},\\hat{h}_{1000},\\hat{h}_{5000}, \\hat{h}_{10000}$*\n",
    "\n",
    "*(f) If $\\hat{h}_n$ is of order $O(\\frac{1}{n^{\\beta}})$ for some $\\beta>0$* we expect that $\\hat{h}=\\frac{c}{n^\\beta}$ for some constant $c_0$ or equivalently, $log(\\hat{h}_n)=log(c)-\\beta log(n)$ hence for n=100, 500, 1000, 5000, 10,000 plot $log(\\hat{h}_n)$ versus $log(n)$. Does the relationship between $log(\\hat{h}_n)$ and $log(n)$ appear to be approximately linear?\n",
    "\n",
    "*(g) Using least-squares regression (function lm) estimate the parameter $\\beta$ in the model  $log(\\hat{h}_n)=log(c)-\\beta log(n)+e$ If $h_{cv}$ is of order $O(\\frac{1}{n^{1/5}})$? why or why not?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 3.3",
   "language": "R",
   "name": "ir33"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
